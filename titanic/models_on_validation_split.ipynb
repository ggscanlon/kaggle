{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load processed, X, y, test\n",
    "file_loc = '/Users/gregscanlon/Documents/Kaggle/titanic/'\n",
    "\n",
    "X = pd.read_excel(file_loc+'X_processed.xlsx')\n",
    "y = pd.read_excel(file_loc+'y_processed.xlsx')\n",
    "test = pd.read_excel(file_loc+'gs_test_processed.xlsx')\n",
    "\n",
    "the_label = 'PassengerId'\n",
    "y.rename(columns={'Unnamed: 0':the_label},inplace=True)\n",
    "\n",
    "X.set_index(the_label,inplace=True)\n",
    "y.set_index(the_label,inplace=True)\n",
    "test.set_index(the_label,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data manually - not to gaussian\n",
    "#adj_fare, Age to 0-1 scale\n",
    "X.loc[:,'fare_norm'] = X['adj_fare'].divide(X['adj_fare'].max())\n",
    "X.loc[:,'age_norm'] = X['Age'].divide(X['Age'].max())\n",
    "\n",
    "X.drop(['adj_fare','Age'],axis=1,inplace=True)\n",
    "\n",
    "test.loc[:,'fare_norm'] = test['adj_fare'].divide(test['adj_fare'].max())\n",
    "test.loc[:,'age_norm'] = test['Age'].divide(test['Age'].max())\n",
    "\n",
    "test.drop(['adj_fare','Age'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 881, 418)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1] == test.shape[1], len(X), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 221)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation set\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42)\n",
    "len(X), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data using sklearn\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9893939393939394\n",
      "test score:  0.9864253393665159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregscanlon/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "clf = LogisticRegression(random_state=0).fit(X, y['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X, y['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test, y_test['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males Only - Log Regression\n",
      "PClass:  1\n",
      "train score:  0.9885057471264368  |test score:  0.9117647058823529\n",
      "PClass:  2\n",
      "train score:  0.9880952380952381  |test score:  1.0\n",
      "PClass:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregscanlon/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/gregscanlon/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9849624060150376  |test score:  0.987012987012987\n",
      ".....\n",
      "Females Only - Log Regression\n",
      "PClass:  1\n",
      "train score:  0.9838709677419355  |test score:  0.9333333333333333\n",
      "PClass:  2\n",
      "train score:  0.9473684210526315  |test score:  0.9473684210526315\n",
      "PClass:  3\n",
      "train score:  1.0  |test score:  0.918918918918919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregscanlon/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/gregscanlon/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#logistic regression on males only\n",
    "to_drop = ['Age','name_len','tix_group']\n",
    "\n",
    "\n",
    "\n",
    "dt_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "print('Males Only - Log Regression')\n",
    "X_male = X[X.m_f==0]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==0]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "\n",
    "    X_experiment = X_male[X_male.Pclass==pclass]\n",
    "    y_experiment = y_male.loc[X_experiment.index]\n",
    "    X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "    y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "    clf = LogisticRegression(random_state=0,solver='lbfgs').fit(X_experiment, y_experiment['Survived'])\n",
    "\n",
    "    dt_dict[pclass] = clf\n",
    "    print('train score: ',clf.score(X_experiment, y_experiment['Survived']),' |test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "    #print('test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    \n",
    "print('.....')\n",
    "print('Females Only - Log Regression')\n",
    "X_male = X[X.m_f==1]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==1]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "\n",
    "    X_experiment = X_male[X_male.Pclass==pclass]\n",
    "    y_experiment = y_male.loc[X_experiment.index]\n",
    "    X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "    y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "    clf = LogisticRegression(random_state=0,solver='lbfgs').fit(X_experiment, y_experiment['Survived'])\n",
    "\n",
    "    dt_dict[pclass] = clf\n",
    "    print('train score: ',clf.score(X_experiment, y_experiment['Survived']),' |test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "    #print('test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - LINEAR\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear').fit(X, y['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X, y['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test, y_test['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM - LINEAR\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear').fit(X_scaled, y['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X_scaled, y['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test_scaled, y_test['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8592814371257484\n",
      "test score:  0.820627802690583\n"
     ]
    }
   ],
   "source": [
    "#SVM - RBF\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf').fit(X_scaled, y['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X_scaled, y['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test_scaled, y_test['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males Only - KNN\n",
      "PClass:  1\n",
      "k =  10  /train score:  0.7011494252873564  /test score:  0.6176470588235294\n",
      "k =  12  /train score:  0.7126436781609196  /test score:  0.6176470588235294\n",
      "k =  14  /train score:  0.6896551724137931  /test score:  0.6176470588235294\n",
      "k =  16  /train score:  0.6896551724137931  /test score:  0.5882352941176471\n",
      "k =  18  /train score:  0.6781609195402298  /test score:  0.6176470588235294\n",
      "PClass:  2\n",
      "k =  10  /train score:  0.8095238095238095  /test score:  0.9583333333333334\n",
      "k =  12  /train score:  0.8095238095238095  /test score:  0.9583333333333334\n",
      "k =  14  /train score:  0.8095238095238095  /test score:  0.9583333333333334\n",
      "k =  16  /train score:  0.8095238095238095  /test score:  0.9583333333333334\n",
      "k =  18  /train score:  0.8095238095238095  /test score:  0.9583333333333334\n",
      "PClass:  3\n",
      "k =  10  /train score:  0.8571428571428571  /test score:  0.8831168831168831\n",
      "k =  12  /train score:  0.8571428571428571  /test score:  0.8831168831168831\n",
      "k =  14  /train score:  0.8571428571428571  /test score:  0.8831168831168831\n",
      "k =  16  /train score:  0.8571428571428571  /test score:  0.8831168831168831\n",
      "k =  18  /train score:  0.8571428571428571  /test score:  0.8831168831168831\n",
      ".......\n",
      "Females Only - KNN\n",
      "PClass:  1\n",
      "k =  10  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  12  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  14  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  16  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  18  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "PClass:  2\n",
      "k =  10  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  12  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  14  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  16  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  18  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "PClass:  3\n",
      "k =  10  /train score:  0.7211538461538461  /test score:  0.5405405405405406\n",
      "k =  12  /train score:  0.6346153846153846  /test score:  0.5675675675675675\n",
      "k =  14  /train score:  0.6057692307692307  /test score:  0.5675675675675675\n",
      "k =  16  /train score:  0.5769230769230769  /test score:  0.5675675675675675\n",
      "k =  18  /train score:  0.5961538461538461  /test score:  0.4594594594594595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_male = X[X.m_f==0]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==0]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "k_neigh_dict = {}\n",
    "\n",
    "print('Males Only - KNN')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in range(10,20,2):\n",
    "        X_experiment = X_male[X_male.Pclass==pclass]\n",
    "        y_experiment = y_male.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "        y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=i).fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        k_neigh_dict[pclass] = clf\n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "print('.......')\n",
    "X_female = X[X.m_f==1]\n",
    "y_female = y.loc[X_female.index]\n",
    "X_test_female = X_test[X_test.m_f==1]\n",
    "y_test_female = y_test.loc[X_test_female.index]\n",
    "\n",
    "k_neigh_dict = {}\n",
    "\n",
    "print('Females Only - KNN')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in range(10,20,2):\n",
    "        X_experiment = X_female[X_female.Pclass==pclass]\n",
    "        y_experiment = y_female.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_female[X_test_female.Pclass==pclass]\n",
    "        y_test_exp = y_test_female.loc[X_test_exp.index]\n",
    "\n",
    "        clf = KNeighborsClassifier(n_neighbors=i).fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        k_neigh_dict[pclass] = clf\n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males Only - DT\n",
      "PClass:  1\n",
      "k =  10  /train score:  1.0  /test score:  1.0\n",
      "k =  20  /train score:  1.0  /test score:  1.0\n",
      "k =  50  /train score:  1.0  /test score:  1.0\n",
      "k =  100  /train score:  1.0  /test score:  1.0\n",
      "k =  500  /train score:  1.0  /test score:  1.0\n",
      "PClass:  2\n",
      "k =  10  /train score:  1.0  /test score:  1.0\n",
      "k =  20  /train score:  1.0  /test score:  1.0\n",
      "k =  50  /train score:  1.0  /test score:  1.0\n",
      "k =  100  /train score:  1.0  /test score:  1.0\n",
      "k =  500  /train score:  1.0  /test score:  1.0\n",
      "PClass:  3\n",
      "k =  10  /train score:  1.0  /test score:  0.974025974025974\n",
      "k =  20  /train score:  1.0  /test score:  0.974025974025974\n",
      "k =  50  /train score:  1.0  /test score:  0.974025974025974\n",
      "k =  100  /train score:  1.0  /test score:  0.974025974025974\n",
      "k =  500  /train score:  1.0  /test score:  0.974025974025974\n",
      ".....\n",
      "Females Only - DT\n",
      "PClass:  1\n",
      "k =  10  /train score:  1.0  /test score:  0.9666666666666667\n",
      "k =  20  /train score:  1.0  /test score:  0.9666666666666667\n",
      "k =  50  /train score:  1.0  /test score:  0.9666666666666667\n",
      "k =  100  /train score:  1.0  /test score:  0.9666666666666667\n",
      "k =  500  /train score:  1.0  /test score:  0.9666666666666667\n",
      "PClass:  2\n",
      "k =  10  /train score:  1.0  /test score:  1.0\n",
      "k =  20  /train score:  1.0  /test score:  1.0\n",
      "k =  50  /train score:  1.0  /test score:  1.0\n",
      "k =  100  /train score:  1.0  /test score:  1.0\n",
      "k =  500  /train score:  1.0  /test score:  1.0\n",
      "PClass:  3\n",
      "k =  10  /train score:  1.0  /test score:  1.0\n",
      "k =  20  /train score:  1.0  /test score:  1.0\n",
      "k =  50  /train score:  1.0  /test score:  1.0\n",
      "k =  100  /train score:  1.0  /test score:  1.0\n",
      "k =  500  /train score:  1.0  /test score:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree on males only\n",
    "from sklearn import tree\n",
    "to_drop = ['Age','name_len','tix_group']\n",
    "\n",
    "X_male = X[X.m_f==0]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==0]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "dt_dict = {}\n",
    "\n",
    "print('Males Only - DT')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in [10,20,50,100,500]:\n",
    "        X_experiment = X_male[X_male.Pclass==pclass]\n",
    "        y_experiment = y_male.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "        y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "        clf = tree.DecisionTreeClassifier().fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        dt_dict[pclass] = clf\n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "\n",
    "print('.....')\n",
    "#Decision Tree on females only\n",
    "\n",
    "to_drop = ['Age','name_len','tix_group']\n",
    "\n",
    "X_male = X[X.m_f==1]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==1]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "dt_dict = {}\n",
    "\n",
    "print('Females Only - DT')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in [10,20,50,100,500]:\n",
    "        X_experiment = X_male[X_male.Pclass==pclass]\n",
    "        y_experiment = y_male.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "        y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "        clf = tree.DecisionTreeClassifier().fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        dt_dict[pclass] = clf\n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"289pt\" height=\"300pt\"\n",
       " viewBox=\"0.00 0.00 289.45 300.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 296)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-296 285.4478,-296 285.4478,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#3c9fe5\" stroke=\"#000000\" d=\"M194.4567,-292C194.4567,-292 33.8842,-292 33.8842,-292 27.8842,-292 21.8842,-286 21.8842,-280 21.8842,-280 21.8842,-226 21.8842,-226 21.8842,-220 27.8842,-214 33.8842,-214 33.8842,-214 194.4567,-214 194.4567,-214 200.4567,-214 206.4567,-220 206.4567,-226 206.4567,-226 206.4567,-280 206.4567,-280 206.4567,-286 200.4567,-292 194.4567,-292\"/>\n",
       "<text text-anchor=\"start\" x=\"29.7773\" y=\"-276.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">last_rg_cat_last_b_rg ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"77.7793\" y=\"-262.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.032</text>\n",
       "<text text-anchor=\"start\" x=\"72.3413\" y=\"-248.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 62</text>\n",
       "<text text-anchor=\"start\" x=\"70\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 61]</text>\n",
       "<text text-anchor=\"start\" x=\"73.5103\" y=\"-220.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Lived</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M92.5118,-171C92.5118,-171 11.829,-171 11.829,-171 5.829,-171 -.171,-165 -.171,-159 -.171,-159 -.171,-119 -.171,-119 -.171,-113 5.829,-107 11.829,-107 11.829,-107 92.5118,-107 92.5118,-107 98.5118,-107 104.5118,-113 104.5118,-119 104.5118,-119 104.5118,-159 104.5118,-159 104.5118,-165 98.5118,-171 92.5118,-171\"/>\n",
       "<text text-anchor=\"start\" x=\"23.5654\" y=\"-155.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"10.3413\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 56</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-127.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 56]</text>\n",
       "<text text-anchor=\"start\" x=\"11.5103\" y=\"-113.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Lived</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M92.8335,-213.7677C86.9225,-202.8991 80.4907,-191.0729 74.5235,-180.1009\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"77.4945,-178.2378 69.642,-171.1252 71.3451,-181.5823 77.4945,-178.2378\"/>\n",
       "<text text-anchor=\"middle\" x=\"62.5584\" y=\"-190.9006\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#61b1ea\" stroke=\"#000000\" d=\"M218.1891,-178C218.1891,-178 134.1518,-178 134.1518,-178 128.1518,-178 122.1518,-172 122.1518,-166 122.1518,-166 122.1518,-112 122.1518,-112 122.1518,-106 128.1518,-100 134.1518,-100 134.1518,-100 218.1891,-100 218.1891,-100 224.1891,-100 230.1891,-106 230.1891,-112 230.1891,-112 230.1891,-166 230.1891,-166 230.1891,-172 224.1891,-178 218.1891,-178\"/>\n",
       "<text text-anchor=\"start\" x=\"129.9116\" y=\"-162.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">tix_group ≤ 3.5</text>\n",
       "<text text-anchor=\"start\" x=\"139.7793\" y=\"-148.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.278</text>\n",
       "<text text-anchor=\"start\" x=\"138.2344\" y=\"-134.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"135.8931\" y=\"-120.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"135.5103\" y=\"-106.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Lived</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M135.5073,-213.7677C140.1348,-205.259 145.0816,-196.1634 149.8747,-187.3502\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.0911,-188.7617 154.7942,-178.3046 146.9417,-185.4173 153.0911,-188.7617\"/>\n",
       "<text text-anchor=\"middle\" x=\"161.8779\" y=\"-198.0801\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M154.9913,-64C154.9913,-64 81.3496,-64 81.3496,-64 75.3496,-64 69.3496,-58 69.3496,-52 69.3496,-52 69.3496,-12 69.3496,-12 69.3496,-6 75.3496,0 81.3496,0 81.3496,0 154.9913,0 154.9913,0 160.9913,0 166.9913,-6 166.9913,-12 166.9913,-12 166.9913,-52 166.9913,-52 166.9913,-58 160.9913,-64 154.9913,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"89.5654\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"80.2344\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"77.8931\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"77.5103\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Lived</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M154.9027,-99.7647C150.1996,-91.0884 145.2039,-81.8721 140.4614,-73.123\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"143.4763,-71.3404 135.6338,-64.2169 137.3223,-74.6763 143.4763,-71.3404\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M269.2261,-64C269.2261,-64 197.1147,-64 197.1147,-64 191.1147,-64 185.1147,-58 185.1147,-52 185.1147,-52 185.1147,-12 185.1147,-12 185.1147,-6 191.1147,0 197.1147,0 197.1147,0 269.2261,0 269.2261,0 275.2261,0 281.2261,-6 281.2261,-12 281.2261,-12 281.2261,-52 281.2261,-52 281.2261,-58 275.2261,-64 269.2261,-64\"/>\n",
       "<text text-anchor=\"start\" x=\"204.5654\" y=\"-48.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"195.2344\" y=\"-34.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"192.8931\" y=\"-20.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"194.8481\" y=\"-6.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Died</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M197.0714,-99.7647C201.6934,-91.0884 206.6031,-81.8721 211.2638,-73.123\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"214.3955,-74.6883 216.0081,-64.2169 208.2175,-71.3971 214.3955,-74.6883\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a220f2a10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dt_dict[1], out_file=None, \n",
    "                      feature_names=X.columns,  \n",
    "                      class_names=['Died','Lived'],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8471615720524017\n",
      "test score:  0.8\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree on males only\n",
    "from sklearn import tree\n",
    "X_female = X[X.m_f==1]\n",
    "y_female = y.loc[X_female.index]\n",
    "X_test_female = X_test[X_test.m_f==1]\n",
    "y_test_female = y_test.loc[X_test_female.index]\n",
    "\n",
    "#drop name_len\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 10).fit(X_female, y_female['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X_female, y_female['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test_female, y_test_female['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males Only - RF\n",
      "PClass:  1\n",
      "k =  10  /train score:  1.0  /test score:  0.9705882352941176\n",
      "k =  20  /train score:  0.9770114942528736  /test score:  0.9705882352941176\n",
      "k =  50  /train score:  0.9885057471264368  /test score:  0.9705882352941176\n",
      "k =  100  /train score:  0.9770114942528736  /test score:  0.9411764705882353\n",
      "k =  500  /train score:  0.9885057471264368  /test score:  0.9705882352941176\n",
      "PClass:  2\n",
      "k =  10  /train score:  0.9047619047619048  /test score:  1.0\n",
      "k =  20  /train score:  0.8928571428571429  /test score:  1.0\n",
      "k =  50  /train score:  0.9404761904761905  /test score:  1.0\n",
      "k =  100  /train score:  0.9047619047619048  /test score:  1.0\n",
      "k =  500  /train score:  0.8928571428571429  /test score:  1.0\n",
      "PClass:  3\n",
      "k =  10  /train score:  0.9774436090225563  /test score:  0.987012987012987\n",
      "k =  20  /train score:  0.9661654135338346  /test score:  0.987012987012987\n",
      "k =  50  /train score:  0.9736842105263158  /test score:  0.987012987012987\n",
      "k =  100  /train score:  0.981203007518797  /test score:  1.0\n",
      "k =  500  /train score:  0.981203007518797  /test score:  1.0\n",
      ".....\n",
      "Females Only - RF\n",
      "PClass:  1\n",
      "k =  10  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  20  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  50  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  100  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "k =  500  /train score:  0.9838709677419355  /test score:  0.9333333333333333\n",
      "PClass:  2\n",
      "k =  10  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  20  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  50  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  100  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "k =  500  /train score:  0.9122807017543859  /test score:  0.9473684210526315\n",
      "PClass:  3\n",
      "k =  10  /train score:  0.9807692307692307  /test score:  0.8918918918918919\n",
      "k =  20  /train score:  0.9903846153846154  /test score:  0.9459459459459459\n",
      "k =  50  /train score:  0.9903846153846154  /test score:  0.972972972972973\n",
      "k =  100  /train score:  1.0  /test score:  0.972972972972973\n",
      "k =  500  /train score:  0.9903846153846154  /test score:  0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_female = X[X.m_f==0]\n",
    "y_female = y.loc[X_female.index]\n",
    "X_test_female = X_test[X_test.m_f==0]\n",
    "y_test_female = y_test.loc[X_test_female.index]\n",
    "\n",
    "print('Males Only - RF')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in [10,20,50,100,500]:\n",
    "        X_experiment = X_female[X_female.Pclass==pclass]\n",
    "        y_experiment = y_female.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_female[X_test_female.Pclass==pclass]\n",
    "        y_test_exp = y_test_female.loc[X_test_exp.index]\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=i,min_samples_leaf = 5).fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    \n",
    "\n",
    "\n",
    "print('.....')\n",
    "\n",
    "X_female = X[X.m_f==1]\n",
    "y_female = y.loc[X_female.index]\n",
    "X_test_female = X_test[X_test.m_f==1]\n",
    "y_test_female = y_test.loc[X_test_female.index]\n",
    "\n",
    "print('Females Only - RF')\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in [10,20,50,100,500]:\n",
    "        X_experiment = X_female[X_female.Pclass==pclass]\n",
    "        y_experiment = y_female.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_female[X_test_female.Pclass==pclass]\n",
    "        y_test_exp = y_test_female.loc[X_test_exp.index]\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=i,min_samples_leaf = 5).fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']),' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "\n",
    "        #print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature tick_surv_rate (0.564057)\n",
      "2. feature m_f (0.128514)\n",
      "3. feature fare_norm (0.042907)\n",
      "4. feature name_len (0.039864)\n",
      "5. feature age_norm (0.037289)\n",
      "6. feature Pclass (0.030593)\n",
      "7. feature cabin_bin (0.022389)\n",
      "8. feature family_size_cat_small (0.020247)\n",
      "9. feature tix_group (0.015505)\n",
      "10. feature ticket_age_range (0.013494)\n",
      "11. feature embark_num (0.010157)\n",
      "12. feature last_age_range (0.009640)\n",
      "13. feature age_cat_baby (0.009252)\n",
      "14. feature age_cat_mid_life (0.009160)\n",
      "15. feature ticket_rg_cat_b_rg (0.008970)\n",
      "16. feature SibSp (0.005947)\n",
      "17. feature ticket_rg_cat_Alone (0.004102)\n",
      "18. feature family_size_cat_single (0.003934)\n",
      "19. feature Parch (0.003570)\n",
      "20. feature last_rg_cat_last_Alone (0.002960)\n",
      "21. feature age_cat_old (0.002690)\n",
      "22. feature age_cat_young_adult (0.002682)\n",
      "23. feature ticket_rg_cat_a_rg (0.002254)\n",
      "24. feature last_rg_cat_last_b_rg (0.002170)\n",
      "25. feature family_size_cat_large (0.001972)\n",
      "26. feature ticket_rg_cat_c_rg (0.001643)\n",
      "27. feature last_rg_cat_last_a_rg (0.001629)\n",
      "28. feature last_rg_cat_last_c_rg (0.001078)\n",
      "29. feature age_cat_child (0.000919)\n",
      "30. feature family_size_cat_medium (0.000218)\n",
      "31. feature title_class_normal (0.000197)\n",
      "32. feature title_class_army_high (0.000000)\n",
      "33. feature title_class_social_high (0.000000)\n",
      "34. feature title_class_social_low (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train 1 RF and see feature importants\n",
    "clf = RandomForestClassifier(n_estimators=100,min_samples_leaf = 5).fit(X, y['Survived'])\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "#std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    " #            axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "ind_list = []\n",
    "for i in indices:\n",
    "    ind_list.append(X.columns[i])\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, ind_list[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), ind_list)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PClass:  1\n",
      "k =  10  /train score:  0.8488372093023255\n",
      "k =  10  /test score:  0.6388888888888888\n",
      "k =  20  /train score:  0.7325581395348837\n",
      "k =  20  /test score:  0.6944444444444444\n",
      "k =  50  /train score:  0.7906976744186046\n",
      "k =  50  /test score:  0.6666666666666666\n",
      "k =  100  /train score:  0.8255813953488372\n",
      "k =  100  /test score:  0.6944444444444444\n",
      "k =  500  /train score:  0.7790697674418605\n",
      "k =  500  /test score:  0.6666666666666666\n",
      "PClass:  2\n",
      "k =  10  /train score:  0.8275862068965517\n",
      "k =  10  /test score:  0.9047619047619048\n",
      "k =  20  /train score:  0.9080459770114943\n",
      "k =  20  /test score:  0.9523809523809523\n",
      "k =  50  /train score:  0.9195402298850575\n",
      "k =  50  /test score:  0.9523809523809523\n",
      "k =  100  /train score:  0.9195402298850575\n",
      "k =  100  /test score:  0.9523809523809523\n",
      "k =  500  /train score:  0.9195402298850575\n",
      "k =  500  /test score:  0.9523809523809523\n",
      "PClass:  3\n",
      "k =  10  /train score:  0.8609022556390977\n",
      "k =  10  /test score:  0.9012345679012346\n",
      "k =  20  /train score:  0.868421052631579\n",
      "k =  20  /test score:  0.9135802469135802\n",
      "k =  50  /train score:  0.8646616541353384\n",
      "k =  50  /test score:  0.9012345679012346\n",
      "k =  100  /train score:  0.868421052631579\n",
      "k =  100  /test score:  0.9012345679012346\n",
      "k =  500  /train score:  0.8646616541353384\n",
      "k =  500  /test score:  0.9012345679012346\n"
     ]
    }
   ],
   "source": [
    "X_male = X[X.m_f==0]\n",
    "y_male = y.loc[X_male.index]\n",
    "X_test_male = X_test[X_test.m_f==0]\n",
    "y_test_male = y_test.loc[X_test_male.index]\n",
    "\n",
    "\n",
    "for pclass in [1,2,3]:\n",
    "    print('PClass: ',pclass)\n",
    "    for i in [10,20,50,100,500]:\n",
    "        X_experiment = X_male[X_male.Pclass==pclass]\n",
    "        y_experiment = y_male.loc[X_experiment.index]\n",
    "        X_test_exp = X_test_male[X_test_male.Pclass==pclass]\n",
    "        y_test_exp = y_test_male.loc[X_test_exp.index]\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=i,min_samples_leaf = 5).fit(X_experiment, y_experiment['Survived'])\n",
    "        \n",
    "        print('k = ',i,' /train score: ',clf.score(X_experiment, y_experiment['Survived']))\n",
    "\n",
    "        print('k = ',i,' /test score: ',clf.score(X_test_exp, y_test_exp['Survived']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  10  /train score:  0.8656036446469249\n",
      "k =  10  /test score:  0.8405797101449275\n",
      "k =  20  /train score:  0.8724373576309795\n",
      "k =  20  /test score:  0.8623188405797102\n",
      "k =  50  /train score:  0.876993166287016\n",
      "k =  50  /test score:  0.8768115942028986\n",
      "k =  100  /train score:  0.8610478359908884\n",
      "k =  100  /test score:  0.8478260869565217\n",
      "k =  500  /train score:  0.8656036446469249\n",
      "k =  500  /test score:  0.8623188405797102\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in [10,20,50,100,500]:\n",
    "    clf = RandomForestClassifier(n_estimators=i,min_samples_leaf = 5).fit(X_male, y_male['Survived'])\n",
    "    \n",
    "    print('k = ',i,' /train score: ',clf.score(X_male, y_male['Survived']))\n",
    "\n",
    "    print('k = ',i,' /test score: ',clf.score(X_test_male, y_test_male['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  10  /train score:  0.8995633187772926\n",
      "k =  10  /test score:  0.8352941176470589\n",
      "k =  20  /train score:  0.8820960698689956\n",
      "k =  20  /test score:  0.8235294117647058\n",
      "k =  50  /train score:  0.8864628820960698\n",
      "k =  50  /test score:  0.8235294117647058\n",
      "k =  100  /train score:  0.8908296943231441\n",
      "k =  100  /test score:  0.8235294117647058\n",
      "k =  500  /train score:  0.8908296943231441\n",
      "k =  500  /test score:  0.8352941176470589\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in [10,20,50,100,500]:\n",
    "    clf = RandomForestClassifier(n_estimators=i, min_samples_leaf = 5).fit(X_female, y_female['Survived'])\n",
    "    \n",
    "    print('k = ',i,' /train score: ',clf.score(X_female, y_female['Survived']))\n",
    "\n",
    "    print('k = ',i,' /test score: ',clf.score(X_test_female, y_test_female['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.8937125748502994\n",
      "test score:  0.8026905829596412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=200).fit(X_scaled,y['Survived'])\n",
    "\n",
    "print('train score: ',clf.score(X_scaled, y['Survived']))\n",
    "\n",
    "print('test score: ',clf.score(X_test_scaled, y_test['Survived']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4cf4ebd5758d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAMME\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          n_estimators=200).fit(X_scaled,y)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train score: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=200).fit(X_scaled,y)\n",
    "\n",
    "print('train score: ',clf.score(X_scaled, y))\n",
    "\n",
    "print('test score: ',clf.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.12876276e-02, 1.23428114e-01, 2.10395965e-02, 1.40467562e-02,\n",
       "       9.91751968e-02, 1.02484052e-01, 2.24069742e-02, 1.26077726e-01,\n",
       "       1.91036464e-02, 1.57523997e-02, 3.17621059e-02, 3.80428893e-02,\n",
       "       1.03491621e-01, 1.81643003e-03, 5.32120500e-03, 5.04979024e-03,\n",
       "       4.70848450e-03, 7.19767602e-03, 1.51425034e-03, 1.41917450e-03,\n",
       "       8.59506074e-04, 1.77458255e-04, 1.13796514e-02, 8.81818886e-03,\n",
       "       7.05618366e-03, 3.52683638e-02, 5.08688653e-05, 1.10430307e-01,\n",
       "       3.37807334e-02, 7.05302267e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "710     True\n",
       "440     True\n",
       "841     True\n",
       "721     True\n",
       "40     False\n",
       "       ...  \n",
       "881     True\n",
       "426     True\n",
       "102     True\n",
       "200    False\n",
       "425     True\n",
       "Name: Survived, Length: 223, dtype: bool"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['Survived'] == clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([710, 721, 486, 245, 622, 448,  31, 674, 397, 794, 236, 205,  24,\n",
       "            791, 363, 803, 281, 197, 773, 768, 540, 358, 255, 779, 175, 494,\n",
       "            166, 389, 713, 339, 287, 513,  97, 293, 276,  79, 579,  66, 600,\n",
       "             50, 855, 585, 644, 658, 297,   6, 458,  98, 573, 853,  26,  56,\n",
       "             82, 535, 391, 469, 410, 200],\n",
       "           dtype='int64', name='PassengerId')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = y_test.index[y_test['Survived'] != clf.predict(X_test)]\n",
    "y_test.index[y_test['Survived'] != clf.predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "remerge = X_test.merge(y_test,how='left',left_index=True,right_index=True)\n",
    "review_incorrect = remerge.loc[wrong]\n",
    "wrong_male = review_incorrect[review_incorrect.m_f==0]\n",
    "wrong_female = review_incorrect[review_incorrect.m_f==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_f\n",
      "Age\n",
      "adj_fare\n",
      "name_len\n",
      "family_size\n",
      "Pclass\n",
      "tix_group\n",
      "embark_num\n",
      "rare_title\n"
     ]
    }
   ],
   "source": [
    "for f in ind_list:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data on 2-4 most important features and eval hist\n",
    "\n",
    "for f in ind_list:\n",
    "    if f == 'm_f':\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    \n",
    "    ind_list[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
